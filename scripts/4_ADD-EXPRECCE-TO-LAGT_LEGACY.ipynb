{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2025-09-10T11:50:33.888270Z",
     "start_time": "2025-09-10T11:50:33.882653Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import os\n",
    "import pickle\n",
    "import json"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Problem: LAGT not defined, just used directly",
   "id": "bf837fb5979b7853",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "LAGT[LAGT[\"lemmatized_sentences\"].isnull()].sample(10)",
   "id": "fde24d929b40ac72"
  },
  {
   "cell_type": "code",
   "id": "400afbff2180c727",
   "metadata": {},
   "source": [
    "# there is an invalid document:\n",
    "row_index = LAGT[LAGT[\"doc_id\"] == \"tlg0530.tlg006\"].index[0]\n",
    "LAGT = LAGT.drop(row_index)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dc7ccca0643a6068",
   "metadata": {},
   "source": [
    "def get_row_data(row):\n",
    "    doc_id = row[\"doc_id\"]\n",
    "    # source = row[\"source\"]\n",
    "    # lemmata_source = row[\"lemmata_source\"]\n",
    "    try:\n",
    "        file_path = target_path + doc_id + \".pickle\"\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            sentences_data = pickle.load(f)\n",
    "        sentences = [sent[2] for sent in sentences_data]\n",
    "        lemmatized_sentences = [[t[1] for t in sent[3] if t[2] in [\"n\", \"a\", \"v\", \"NOUN\", \"PROPN\", \"ADJ\", \"VERB\"]] for sent in sentences_data]\n",
    "        #source = \"glaux1\"\n",
    "        #lemmata_source = \"glaux1\"\n",
    "    except:\n",
    "        sentences = None\n",
    "        lemmatized_sentences = None\n",
    "    return sentences, lemmatized_sentences # , source, lemmata_source"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "32cbd60ca1cbb09b",
   "metadata": {},
   "source": "result = exprecce.apply(lambda row: pd.Series(get_row_data(row)), axis=1)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6e3f4d588461ef75",
   "metadata": {},
   "source": [
    "result.sample(10)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4daede93f0679002",
   "metadata": {},
   "source": [
    "LAGT[\"sentences\"] = result[0]  # Extract sentences\n",
    "LAGT[\"lemmatized_sentences\"] = result[1]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b51112a4c6cbc801",
   "metadata": {},
   "source": [
    "LAGT.loc[1963]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c70f7f4e01fce4e5",
   "metadata": {},
   "source": [
    "LAGT[\"lemmatized_sentences\"].isnull().sum()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8379f12715ae3042",
   "metadata": {},
   "source": [
    "len(LAGT)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "22f57f6a34133b68",
   "metadata": {},
   "source": [
    "LAGT = LAGT.drop_duplicates(subset=\"doc_id\", keep=\"first\")\n",
    "len(LAGT)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9d7c16cc58d52f26",
   "metadata": {},
   "source": [
    "### Checking what is in what shape"
   ]
  },
  {
   "cell_type": "code",
   "id": "7622153cac2c4d00",
   "metadata": {},
   "source": [
    "LAGT[LAGT[\"source\"]==\"exprecce\"]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7ee7899f3783e2b3",
   "metadata": {},
   "source": [
    "def get_wordcout(doc_id):\n",
    "    try:\n",
    "        file_path = target_path + doc_id + \".pickle\"\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            sentences_data = pickle.load(f)\n",
    "        wordcount = sum([len(sent_data[3]) for sent_data in sentences_data])\n",
    "    except:\n",
    "        wordcount = 0\n",
    "    return wordcount"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6c459f9ecaf37068",
   "metadata": {},
   "source": [
    "LAGT[\"wordcount\"] = LAGT[\"doc_id\"].apply(get_wordcout)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f2e02bb33e8a0d01",
   "metadata": {},
   "source": [
    "LAGT[\"wordcount\"].sum()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c645212c88e0f9a5",
   "metadata": {},
   "source": [
    "lemmatized_sentences = [s for work in LAGT[\"lemmatized_sentences\"] for s in work]\n",
    "lemmatized_sentences[:10]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f30d1d7c0da32799",
   "metadata": {},
   "source": [
    "# update lemmatacount\n",
    "LAGT[\"lemmatacount\"] = LAGT[\"lemmatized_sentences\"].apply(lambda x: len([l for s in x for l in s]))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "122a09433140d841",
   "metadata": {},
   "source": [
    "LAGT[\"lemmatacount\"]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "633d1c487eee632e",
   "metadata": {},
   "source": [
    "LAGT['lemmata_source'] = LAGT['lemmata_source'].fillna(\"grecy\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1efa74003d1bc711",
   "metadata": {},
   "source": [
    "placeholder = \"glaux_tmp\"\n",
    "LAGT['lemmata_source'] = LAGT['lemmata_source'].replace(\"glaux\", placeholder)\n",
    "LAGT['lemmata_source'] = LAGT['lemmata_source'].replace(placeholder, \"glaux1\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1e076645b5f45e68",
   "metadata": {},
   "source": [
    "LAGT.groupby(\"lemmata_source\").size() #.isnull().sum()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "69846eca16510706",
   "metadata": {},
   "source": [
    "LAGT.groupby(\"source\").size() #.isnull().sum()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ed0da0c4e831c617",
   "metadata": {},
   "source": [
    "LAGT.columns"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1274b1266c3669ea",
   "metadata": {},
   "source": [
    "LAGT = LAGT[['author_id', 'doc_id', 'filename', 'author', 'title',  'sentences', 'lemmatized_sentences', 'source', 'lemmata_source', 'not_before', 'not_after', 'tlg_epithet', 'genre', 'provenience', 'wordcount', 'lemmatacount', ]]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f073f8465979a703",
   "metadata": {},
   "source": [
    "LAGT[\"title\"].fillna(\"\", inplace=True)\n",
    "LAGT[\"author\"].fillna(\"\", inplace=True)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "63800e28ee3d3fe8",
   "metadata": {},
   "source": [
    "LAGT[LAGT[\"author\"].str.contains(\"Septuagint\")]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4f803faa202c8250",
   "metadata": {},
   "source": [
    "LAGT[LAGT[\"lemmata_source\"]==\"grecy\"].sample(10)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b280b058de859093",
   "metadata": {},
   "source": [
    "LAGT.to_parquet(\"../data/large_files/LAGT_grecy.parquet\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f40382173a3b6107",
   "metadata": {},
   "source": [
    "# save metadata for future usage\n",
    "LAGT[['author_id', 'doc_id', 'filename', 'author', 'title', 'source', 'lemmata_source', 'not_before',\n",
    "       'not_after', 'tlg_epithet', 'genre', 'provenience', 'wordcount',\n",
    "       'lemmatacount']].to_csv(\"../data/LAGT_v4-0_metadata.csv\", index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8995b7b9cba51cea",
   "metadata": {},
   "source": [
    "### From sents_data pickles to jsons"
   ]
  },
  {
   "cell_type": "code",
   "id": "d4bd6a8efac2cfa7",
   "metadata": {},
   "source": [
    "source_path = \"../data/large_files/sents_data/\"\n",
    "target_path = \"../data/large_files/sents_data_jsons/\"\n",
    "try:\n",
    "    os.mkdir(target_path)\n",
    "except:\n",
    "    pass"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5c998305369975d0",
   "metadata": {},
   "source": [
    "fn = \"tlg0527.tlg048.pickle\"\n",
    "with open(source_path + fn, \"rb\") as f:\n",
    "    sents_data = pickle.load(f)\n",
    "sents_data[:10]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "81d94363dc87bf04",
   "metadata": {},
   "source": [
    "reformat_tags_dict = {\n",
    "    \"NOUN\": \"n\",\n",
    "    \"VERB\": \"v\",\n",
    "    \"ADJ\": \"a\",\n",
    "    \"ADV\": \"r\",\n",
    "    \"PRON\": \"p\",\n",
    "    \"DET\": \"l\",\n",
    "    \"ADP\": \"r\",\n",
    "    \"CCONJ\": \"c\",\n",
    "    \"SCONJ\": \"c\",\n",
    "    \"PROPN\": \"n\",\n",
    "    \"PUNCT\": \"u\",\n",
    "    \"n\" : \"n\",\n",
    "    \"v\": \"v\",\n",
    "    \"a\": \"a\",\n",
    "    \"r\": \"r\",\n",
    "    \"p\": \"p\",\n",
    "    \"l\": \"l\",\n",
    "    \"c\": \"c\",\n",
    "    \"u\": \"u\" # Assuming punctuation remains \"u\"\n",
    "}\n",
    "\n",
    "def reformat_tags(tag):\n",
    "    try:\n",
    "        return reformat_tags_dict[tag]\n",
    "    except:\n",
    "        return \"x\"\n",
    "    \n",
    "for fn in os.listdir(source_path):\n",
    "    doc_id =  fn.rpartition(\".\")[0]\n",
    "    with open(source_path + fn, \"rb\") as f:\n",
    "        sents_data = pickle.load(f)\n",
    "    sents_data_updated = []\n",
    "    for id, sent_n, sent_text, sent_data in sents_data:\n",
    "        sent_data_updated = [(t[0], t[1], reformat_tags(t[2]), t[3]) for t in sent_data]\n",
    "        sents_data_updated.append((doc_id, sent_n, sent_text, sent_data_updated))\n",
    "    with open(target_path + doc_id + \".json\", \"w\") as f:\n",
    "        json.dump(sents_data_updated, f)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a83d70c6bc470b08",
   "metadata": {},
   "source": [
    "\n",
    "fn = \"tlg2640.tlg001.json\"\n",
    "with open(target_path + fn, \"rb\") as f:\n",
    "    sents_data = json.load(f)\n",
    "sents_data[:10]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "65b997acb7d5379d",
   "metadata": {},
   "source": [
    "LAGT = pd.read_parquet(\"../data/large_files/LAGT_v4-0.parquet\")\n",
    "LAGT.head()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5c525b5c5455e0d2",
   "metadata": {},
   "source": [
    "path = \"../data/large_files/sents_data/\"\n",
    "LAGT[LAGT[\"doc_id\"].apply(lambda x: f\"{x}.pickle\" not in os.listdir(path))]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8e880f5bc7eab863",
   "metadata": {},
   "source": [
    "len(set(LAGT[\"doc_id\"]))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6f06f485caf1ef6a",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8c8e70716c0c901e",
   "metadata": {},
   "source": [
    "### Backup of an old approach..."
   ]
  },
  {
   "cell_type": "code",
   "id": "61b2d35b56c90ac5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# put the string cleaning, doc creation and lemmata together into one function\n",
    "def from_string_to_lemsents(string):\n",
    "    try:    \n",
    "        doc = get_doc(clean_string(string), segment_len=50000)\n",
    "        lemmatized_sentences = get_lemmatized_sentences(doc)\n",
    "    except:\n",
    "        lemmatized_sentences = None\n",
    "    return lemmatized_sentences"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e31e2423065c010c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "grecy_lemmatized_list = []\n",
    "def get_grecy_lemmata(string, lemmatized_sentences, doc_id):\n",
    "    if lemmatized_sentences == None:\n",
    "        lemmatized_sentences = from_string_to_lemsents(string)\n",
    "        grecy_lemmatized_list.append(doc_id)\n",
    "        print(len(grecy_lemmatized_list), doc_id, len(string))\n",
    "    return lemmatized_sentences\n",
    "\n",
    "#sample_lemmatized_sentences = LAGT.sample(10, random_state=1).apply(lambda row: get_grecy_lemmata(row[\"string\"], row[\"lemmatized_sentences\"], row[\"doc_id\"]), axis=1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "77840f22a24c5e34",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#sample_lemmatized_sentences"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "caa604192ce8279b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#LAGT.loc[sample_lemmatized_sentences.index]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "25df064a122f9268",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#grecy_lemmatized_list"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "45397b2d3414e40b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Applying the main funtion"
   ]
  },
  {
   "cell_type": "code",
   "id": "819118863f791d2c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "%%time\n",
    "### will be time consuming...\n",
    "LAGT[\"lemmatized_sentences\"] = LAGT.apply(lambda row: get_grecy_lemmata(row[\"string\"], row[\"lemmatized_sentences\"], row[\"doc_id\"]), axis=1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "724f030638d3ee99",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "LAGT[LAGT[\"lemmatized_sentences\"].isnull()]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "75234740017ec51b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "missing_i = LAGT[LAGT[\"lemmatized_sentences\"].isnull()].index"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "583b8c87f441cdf7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "string = LAGT[LAGT[\"lemmatized_sentences\"].isnull()][\"string\"].tolist()[1]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b9e8c13a414590f8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "type(string)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "92813304bd3748d5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "cleaned_string = clean_string(string)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bc60dd77a1af1fb6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "cleaned_string = re.sub(\"\\.{3}\\.*\", \"...\", cleaned_string)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "847bed545df5c5bb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "doc = nlp(cleaned_string)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1e51658f2a119f4f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "def dealing_with_missing(string):\n",
    "    string = str(string)\n",
    "    cleaned_string = clean_string(string)\n",
    "    cleaned_string = re.sub(\"\\.{3}\\.*\", \"...\", cleaned_string)\n",
    "    doc = nlp(cleaned_string)\n",
    "    lemmatized_sentences = get_lemmatized_sentences(doc)\n",
    "    return lemmatized_sentences\n",
    "\n",
    "lemmatized_missing = LAGT[LAGT[\"lemmatized_sentences\"].isnull()][\"string\"].apply(dealing_with_missing)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2de20004ea75ef75",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "lemmatized_missing"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "92fb0b37f47a43d4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "LAGT.loc[missing_i, \"lemmatized_sentences\"] = lemmatized_missing"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "eaced2b4b440be20",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "LAGT.sample(10, random_state=1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "75b92222334b852b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "LAGT[\"lemmata_source\"] = LAGT[\"lemmata_source\"].apply(lambda x: \"grecy\" if x is None else x)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cad373b8ae1d22d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Simple explorations of what is in the lemmata"
   ]
  },
  {
   "cell_type": "code",
   "id": "75f49bd3dad6d762",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "lemmata_series = LAGT[\"lemmatized_sentences\"].apply(lambda x: [l for s in x for l in s])\n",
    "lemmata_all = [l for lemmata in lemmata_series for l in lemmata]\n",
    "nltk.FreqDist(lemmata_all).most_common()[:100]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a1682cfdfd4fd5d8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "lemmata_series = LAGT[LAGT[\"lemmata_source\"]==\"grecy\"][\"lemmatized_sentences\"].apply(lambda x: [l for s in x for l in s])\n",
    "lemmata_all = [l for lemmata in lemmata_series for l in lemmata]\n",
    "nltk.FreqDist(lemmata_all).most_common()[:100]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c1f3ff14ba3c6824",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "LAGT.to_json(\"../data/large_files/LAGT_grecy_20240116.json\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b2e93c867bff5254",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#s = sddk.cloudSession(\"sciencedata.dk\", \"SDAM_root\", \"648597@au.dk\")\n",
    "s.write_file(\"SDAM_data/AGT/LAGT_grecy_20240116.json\", LAGT)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ebbe618d59a51818",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
